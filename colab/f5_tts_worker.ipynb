{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéôÔ∏è F5-TTS Worker ‚Äî Voice Cloning on Colab T4\n",
        "\n",
        "This notebook uses F5-TTS for high-quality, natural-sounding narration with voice cloning.\n",
        "Provide a 10-15s reference audio clip and F5-TTS will generate all narration in that voice.\n",
        "\n",
        "**Advantages over Kokoro:**\n",
        "- Voice cloning from a short reference clip\n",
        "- More natural prosody, emphasis, and pacing\n",
        "- GPU-bound model ‚Äî T4 provides real speedup (RTF ~0.3-0.5)\n",
        "\n",
        "**Setup:** Runtime ‚Üí Change runtime type ‚Üí T4 GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q f5-tts soundfile\n",
        "# Verify GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configure Paths\n",
        "\n",
        "Job directory structure on Google Drive:\n",
        "```\n",
        "My Drive/\n",
        "  autonomous-recording/\n",
        "    f5-tts-jobs/          ‚Üê separate from kokoro jobs\n",
        "      <job-id>/\n",
        "        request.json      ‚Üê local machine writes this\n",
        "        ref_audio.wav     ‚Üê reference voice clip (copied from settings)\n",
        "        audio/            ‚Üê worker writes WAVs here\n",
        "        done.marker       ‚Üê worker writes when complete\n",
        "    voice-refs/           ‚Üê store your reference voice clips here\n",
        "      teacher-voice.wav\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "DRIVE_BASE = \"/content/drive/MyDrive/autonomous-recording/f5-tts-jobs\"\n",
        "VOICE_REFS_DIR = \"/content/drive/MyDrive/autonomous-recording/voice-refs\"\n",
        "\n",
        "os.makedirs(DRIVE_BASE, exist_ok=True)\n",
        "os.makedirs(VOICE_REFS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Job directory: {DRIVE_BASE}\")\n",
        "print(f\"Voice refs directory: {VOICE_REFS_DIR}\")\n",
        "\n",
        "# List existing voice references\n",
        "refs = [f for f in os.listdir(VOICE_REFS_DIR) if f.endswith('.wav')] if os.path.exists(VOICE_REFS_DIR) else []\n",
        "if refs:\n",
        "    print(f\"\\nAvailable voice references: {refs}\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  No voice references found in {VOICE_REFS_DIR}\")\n",
        "    print(\"Upload a 10-15s WAV clip of the target voice to that directory.\")\n",
        "    print(\"The default F5-TTS reference voice will be used as fallback.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Verify GPU + PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_mem / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No GPU detected. Check Runtime ‚Üí Change runtime type ‚Üí T4 GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Initialize F5-TTS Model\n",
        "\n",
        "First load downloads the model (~1.2 GB). Subsequent runs use the cached version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from f5_tts.api import F5TTS\n",
        "\n",
        "print(\"Loading F5-TTS model (first run downloads ~1.2 GB)...\")\n",
        "t0 = time.time()\n",
        "f5tts = F5TTS(model_type=\"F5-TTS\", ckpt_file=\"\", device=None)  # auto-detect GPU\n",
        "print(f\"‚úì Model loaded in {time.time() - t0:.1f}s\")\n",
        "\n",
        "# Warm up\n",
        "print(\"Warming up GPU...\")\n",
        "t0 = time.time()\n",
        "_ = f5tts.infer(\n",
        "    ref_file=\"\",  # uses built-in default reference\n",
        "    ref_text=\"\",\n",
        "    gen_text=\"Hello, this is a warm up sentence for the GPU.\",\n",
        "    seed=42,\n",
        ")\n",
        "print(f\"‚úì Warm-up done in {time.time() - t0:.2f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Upload a Voice Reference (Optional)\n",
        "\n",
        "Upload a 10-15 second WAV clip of the voice you want to clone.\n",
        "Place it in `My Drive/autonomous-recording/voice-refs/`.\n",
        "\n",
        "**Tips for good reference audio:**\n",
        "- 10-15 seconds of clear speech, no background noise\n",
        "- Normal speaking pace (not too fast, not too slow)\n",
        "- Conversational tone matching your tutorial style\n",
        "- WAV format, 16kHz+ sample rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You can also upload directly from your local machine:\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()  # opens file picker\n",
        "# for name, data in uploaded.items():\n",
        "#     dest = os.path.join(VOICE_REFS_DIR, name)\n",
        "#     with open(dest, 'wb') as f:\n",
        "#         f.write(data)\n",
        "#     print(f\"Saved {name} to {dest}\")\n",
        "\n",
        "# List available references\n",
        "refs = [f for f in os.listdir(VOICE_REFS_DIR) if f.endswith('.wav')] if os.path.exists(VOICE_REFS_DIR) else []\n",
        "print(f\"Voice references: {refs if refs else 'none (will use F5-TTS default)'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. F5-TTS Job Processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import soundfile as sf\n",
        "import tempfile\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def process_f5_tts_job(job_dir: str) -> dict:\n",
        "    \"\"\"Process an F5-TTS job from a directory on Google Drive.\n",
        "\n",
        "    request.json format:\n",
        "    {\n",
        "        \"ref_audio\": \"teacher-voice.wav\",     # filename in voice-refs/ or path\n",
        "        \"ref_text\": \"Transcription of the reference audio.\",\n",
        "        \"speed\": 1.0,\n",
        "        \"seed\": 42,\n",
        "        \"nfe_step\": 32,\n",
        "        \"steps\": [\n",
        "            {\"id\": \"step-01\", \"narration\": \"Text to synthesize...\"},\n",
        "            ...\n",
        "        ]\n",
        "    }\n",
        "    \"\"\"\n",
        "    request_path = os.path.join(job_dir, \"request.json\")\n",
        "    audio_dir = os.path.join(job_dir, \"audio\")\n",
        "    done_marker = os.path.join(job_dir, \"done.marker\")\n",
        "    error_marker = os.path.join(job_dir, \"error.marker\")\n",
        "\n",
        "    if os.path.exists(done_marker):\n",
        "        return {\"status\": \"already_done\", \"job_dir\": job_dir}\n",
        "\n",
        "    if not os.path.exists(request_path):\n",
        "        return {\"status\": \"no_request\", \"job_dir\": job_dir}\n",
        "\n",
        "    os.makedirs(audio_dir, exist_ok=True)\n",
        "\n",
        "    with open(request_path, \"r\") as f:\n",
        "        request = json.load(f)\n",
        "\n",
        "    # Resolve reference audio\n",
        "    ref_audio_name = request.get(\"ref_audio\", \"\")\n",
        "    ref_text = request.get(\"ref_text\", \"\")\n",
        "    speed = float(request.get(\"speed\", 1.0))\n",
        "    seed = request.get(\"seed\", None)\n",
        "    nfe_step = int(request.get(\"nfe_step\", 32))\n",
        "    steps = request.get(\"steps\", [])\n",
        "\n",
        "    # Find reference audio file\n",
        "    ref_file = \"\"\n",
        "    if ref_audio_name:\n",
        "        # Check job directory first (uploaded with job)\n",
        "        job_ref = os.path.join(job_dir, ref_audio_name)\n",
        "        if os.path.exists(job_ref):\n",
        "            ref_file = job_ref\n",
        "        else:\n",
        "            # Check voice-refs directory\n",
        "            refs_ref = os.path.join(VOICE_REFS_DIR, ref_audio_name)\n",
        "            if os.path.exists(refs_ref):\n",
        "                ref_file = refs_ref\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è  Reference audio '{ref_audio_name}' not found, using F5-TTS default\")\n",
        "\n",
        "    results = []\n",
        "    total_duration = 0.0\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing F5-TTS job: {os.path.basename(job_dir)}\")\n",
        "    print(f\"Ref audio: {ref_file or '(F5-TTS default)'} | Speed: {speed} | Steps: {len(steps)}\")\n",
        "    print(f\"NFE steps: {nfe_step} | Seed: {seed or 'random'}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    try:\n",
        "        for idx, step in enumerate(steps, 1):\n",
        "            step_id = str(step[\"id\"])\n",
        "            narration = str(step[\"narration\"]).strip()\n",
        "            wav_path = os.path.join(audio_dir, f\"step-{step_id}.wav\")\n",
        "\n",
        "            # Skip if already generated\n",
        "            if os.path.exists(wav_path) and os.path.getsize(wav_path) > 0:\n",
        "                data, sr = sf.read(wav_path)\n",
        "                duration = len(data) / sr\n",
        "                print(f\"  [{idx}/{len(steps)}] ‚ôª Reused {os.path.basename(wav_path)} ({duration:.2f}s)\")\n",
        "                results.append({\"id\": step_id, \"duration\": duration, \"reused\": True})\n",
        "                total_duration += duration\n",
        "                continue\n",
        "\n",
        "            t0 = time.time()\n",
        "            wav, sample_rate, _ = f5tts.infer(\n",
        "                ref_file=ref_file,\n",
        "                ref_text=ref_text,\n",
        "                gen_text=narration,\n",
        "                nfe_step=nfe_step,\n",
        "                speed=speed,\n",
        "                seed=seed,\n",
        "            )\n",
        "            elapsed = time.time() - t0\n",
        "            duration = len(wav) / sample_rate\n",
        "\n",
        "            # Write atomically\n",
        "            tmp_fd, tmp_path = tempfile.mkstemp(suffix=\".wav\", dir=audio_dir)\n",
        "            os.close(tmp_fd)\n",
        "            sf.write(tmp_path, wav, sample_rate)\n",
        "            os.replace(tmp_path, wav_path)\n",
        "\n",
        "            rtf = elapsed / duration if duration > 0 else 0\n",
        "            print(f\"  [{idx}/{len(steps)}] ‚úì {os.path.basename(wav_path)} ({duration:.2f}s audio, {elapsed:.2f}s gen, RTF={rtf:.2f})\")\n",
        "            results.append({\"id\": step_id, \"duration\": duration, \"gen_time\": elapsed})\n",
        "            total_duration += duration\n",
        "\n",
        "        # Write completion marker\n",
        "        completion = {\n",
        "            \"status\": \"completed\",\n",
        "            \"engine\": \"f5-tts\",\n",
        "            \"total_duration\": total_duration,\n",
        "            \"steps_generated\": len(results),\n",
        "            \"results\": results,\n",
        "            \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
        "        }\n",
        "        with open(done_marker, \"w\") as f:\n",
        "            json.dump(completion, f, indent=2)\n",
        "\n",
        "        print(f\"\\n‚úì Job complete: {len(results)} steps, {total_duration:.2f}s total audio\")\n",
        "        return completion\n",
        "\n",
        "    except Exception as e:\n",
        "        error_info = {\"status\": \"error\", \"error\": str(e), \"step\": idx if 'idx' in dir() else -1}\n",
        "        with open(error_marker, \"w\") as f:\n",
        "            json.dump(error_info, f, indent=2)\n",
        "        print(f\"\\n‚úó Job failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return error_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Job Watcher Loop\n",
        "\n",
        "Polls the Drive job directory for new F5-TTS requests.\n",
        "\n",
        "**To stop:** Interrupt the cell (‚¨õ stop button)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "POLL_INTERVAL = 5  # seconds\n",
        "\n",
        "\n",
        "def watch_for_jobs():\n",
        "    \"\"\"Watch for new F5-TTS jobs.\"\"\"\n",
        "    print(f\"üëÄ Watching for F5-TTS jobs in: {DRIVE_BASE}\")\n",
        "    print(f\"   Poll interval: {POLL_INTERVAL}s\")\n",
        "    print(f\"   Press ‚¨õ to stop\\n\")\n",
        "\n",
        "    processed = set()\n",
        "\n",
        "    # Skip already-completed jobs\n",
        "    if os.path.exists(DRIVE_BASE):\n",
        "        for name in os.listdir(DRIVE_BASE):\n",
        "            job_dir = os.path.join(DRIVE_BASE, name)\n",
        "            if os.path.isdir(job_dir):\n",
        "                done = os.path.join(job_dir, \"done.marker\")\n",
        "                error = os.path.join(job_dir, \"error.marker\")\n",
        "                if os.path.exists(done) or os.path.exists(error):\n",
        "                    processed.add(name)\n",
        "\n",
        "    print(f\"   Skipping {len(processed)} already-processed job(s)\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            if not os.path.exists(DRIVE_BASE):\n",
        "                time.sleep(POLL_INTERVAL)\n",
        "                continue\n",
        "\n",
        "            for name in sorted(os.listdir(DRIVE_BASE)):\n",
        "                if name in processed:\n",
        "                    continue\n",
        "\n",
        "                job_dir = os.path.join(DRIVE_BASE, name)\n",
        "                if not os.path.isdir(job_dir):\n",
        "                    continue\n",
        "\n",
        "                request_path = os.path.join(job_dir, \"request.json\")\n",
        "                if not os.path.exists(request_path):\n",
        "                    continue\n",
        "\n",
        "                now = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
        "                print(f\"\\n[{now}] üìã New F5-TTS job detected: {name}\")\n",
        "\n",
        "                result = process_f5_tts_job(job_dir)\n",
        "                processed.add(name)\n",
        "\n",
        "                now = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
        "                print(f\"[{now}] ‚úì Job {name} ‚Üí {result.get('status', 'unknown')}\")\n",
        "\n",
        "            time.sleep(POLL_INTERVAL)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nüõë Watcher stopped.\")\n",
        "            break\n",
        "\n",
        "\n",
        "watch_for_jobs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Quick Test\n",
        "\n",
        "Generate a test audio to hear the voice quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick test with default voice\n",
        "test_text = \"Welcome to this tutorial. Today we'll learn about bubble sort, a simple comparison-based sorting algorithm. It is not the fastest, but it is a great starting point.\"\n",
        "\n",
        "# To test with YOUR voice, set ref_file and ref_text:\n",
        "# ref_file = os.path.join(VOICE_REFS_DIR, \"teacher-voice.wav\")\n",
        "# ref_text = \"The transcription of what is said in the reference audio.\"\n",
        "ref_file = \"\"  # empty = use F5-TTS built-in default\n",
        "ref_text = \"\"\n",
        "\n",
        "t0 = time.time()\n",
        "wav, sr, _ = f5tts.infer(\n",
        "    ref_file=ref_file,\n",
        "    ref_text=ref_text,\n",
        "    gen_text=test_text,\n",
        "    seed=42,\n",
        ")\n",
        "elapsed = time.time() - t0\n",
        "duration = len(wav) / sr\n",
        "\n",
        "print(f\"Generated {duration:.2f}s of audio in {elapsed:.2f}s (RTF: {elapsed/duration:.2f})\")\n",
        "\n",
        "sf.write(\"/tmp/test_f5tts.wav\", wav, sr)\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "display(Audio(wav, rate=sr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Test with Voice Clone\n",
        "\n",
        "Test with a reference voice clip from your Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment and set your reference audio:\n",
        "# ref_file = os.path.join(VOICE_REFS_DIR, \"teacher-voice.wav\")\n",
        "# ref_text = \"The exact words spoken in the reference audio file.\"\n",
        "#\n",
        "# test_text = \"Welcome to this tutorial. Today we will learn about bubble sort.\"\n",
        "#\n",
        "# wav, sr, _ = f5tts.infer(\n",
        "#     ref_file=ref_file,\n",
        "#     ref_text=ref_text,\n",
        "#     gen_text=test_text,\n",
        "#     seed=42,\n",
        "# )\n",
        "#\n",
        "# from IPython.display import Audio, display\n",
        "# display(Audio(wav, rate=sr))"
      ]
    }
  ]
}
